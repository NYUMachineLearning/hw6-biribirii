---
title: "HW6"
author: "Brian Chang"
date: "2019/11/23"
output:
  html_document: default
  pdf_document: default
---

```{r load relevant libraries, include=FALSE}
library(tidyverse)
library(mlbench)
library(caret)
library(pROC)
```

## Load Data

```{r}
data("PimaIndiansDiabetes")

PimaIndiansDiabetes[is.na(PimaIndiansDiabetes)] = 0

train_size = floor(0.75 * nrow(PimaIndiansDiabetes))
train_pos <- sample(seq_len(nrow(PimaIndiansDiabetes)), size = train_size)

train_classification <- PimaIndiansDiabetes[train_pos, ]
test_classification <- PimaIndiansDiabetes[-train_pos, ]
```

## Support Vector Machine with Linear Kernel
* The SVM with linear kernel has a relatively moderate accuracy of 78.7% when applied to the test set. 
* The AUC is 0.8121.

```{r}
set.seed(100)
control = trainControl(method = "repeatedcv", repeats = 5, classProbs = T, savePredictions = T)

svm = train(diabetes ~ .,  data = train_classification, method = "svmLinear", tuneLength = 10, trControl = control)

svm
```


```{r}
roc(predictor = svm$pred$pos, response = svm$pred$obs)$auc

plot(x = roc(predictor = svm$pred$pos, response = svm$pred$obs)$specificities, y = roc(predictor = svm$pred$pos, response = svm$pred$obs)$sensitivities, col= "blue", xlim = c(1, 0), type ="l", ylab = "Sensitivity", xlab = "Specificity")
```


```{r}
svm_test = predict(svm, newdata = test_classification)
confusionMatrix(svm_test, reference = test_classification$diabetes)
```

## Support Vector Machine with Radial Kernel
* We see here that the SVM with raidal kernel performed worse in comparsion to the linear kernel with an accuracy of 74.0% when applied to the test set.

```{r}
set.seed(123)
control = trainControl(method = "repeatedcv", repeats = 5, classProbs = T, savePredictions = T)

svm_radial = train(diabetes ~ .,  data = train_classification, method = "svmRadial", tuneLength = 10, trControl = control)

svm_radial
```


```{r}
roc(predictor = svm_radial$pred$pos, response = svm_radial$pred$obs)$auc

plot(x = roc(predictor = svm_radial$pred$pos, response = svm_radial$pred$obs)$specificities, y = roc(predictor = svm_radial$pred$pos, response = svm_radial$pred$obs)$sensitivities, col= "blue", xlim = c(1, 0), type ="l", ylab = "Sensitivity", xlab = "Specificity")
```


```{r}
svm_radial_test = predict(svm_radial, newdata = test_classification)
confusionMatrix(svm_radial_test, reference = test_classification$diabetes)
```

## Simulated Annealing followed by Support Vector Machine with Linear Kernel
* We select for the top 5 variables according to the simmulated annealing.
```{r}
sa_ctrl <- safsControl(functions = rfSA,
                       method = "repeatedcv",
                       repeats = 5,
                       improve = 50)
set.seed(10)
rf_sa <- safs(x = PimaIndiansDiabetes[,1:8], y = PimaIndiansDiabetes[,9],
              iters = 10,
              safsControl = sa_ctrl)
rf_sa
```

```{r}
set.seed(321)
control = trainControl(method = "repeatedcv", repeats = 5, classProbs = T, savePredictions = T)

svm_feature = train(diabetes ~ glucose + age + insulin + mass + pregnant,  data = train_classification, method = "svmLinear", tuneLength = 10, trControl = control)

svm_feature
```

* The AUC for this model is slightly lower than the previous model but by a negligible difference.

```{r}
roc(predictor = svm_feature$pred$pos, response = svm_feature$pred$obs)$auc

plot(x = roc(predictor = svm_feature$pred$pos, response = svm_feature$pred$obs)$specificities, y = roc(predictor = svm_feature$pred$pos, response = svm_feature$pred$obs)$sensitivities, col= "blue", xlim = c(1, 0), type ="l", ylab = "Sensitivity", xlab = "Specificity")
```

* When applied to the test set, the model performs with a moderate accuracy of 78.1%, which is comparable to the SVM with linear kernel with all the predictor variables.
```{r}
svm_feature_test = predict(svm_feature, newdata = test_classification)
confusionMatrix(svm_feature_test, reference = test_classification$diabetes)
```

## SVM with Radial Kernel after Feature Selection
* Accuracy is slightly lower than previous SVM with all predictor variables.
* The lower accuracy may be accounted for when taking into account that because we removed some predictors from the model, we may be over-fitting our SVM as a result.
```{r}
set.seed(321)
control = trainControl(method = "repeatedcv", repeats = 5, classProbs = T, savePredictions = T)

svm_feature = train(diabetes ~ glucose + age + insulin + mass + pregnant,  data = train_classification, method = "svmRadial", tuneLength = 10, trControl = control)

svm_feature
```


```{r}
roc(predictor = svm_feature$pred$pos, response = svm_feature$pred$obs)$auc

plot(x = roc(predictor = svm_feature$pred$pos, response = svm_feature$pred$obs)$specificities, y = roc(predictor = svm_feature$pred$pos, response = svm_feature$pred$obs)$sensitivities, col= "blue", xlim = c(1, 0), type ="l", ylab = "Sensitivity", xlab = "Specificity")
```

```{r}
svm_feature_test = predict(svm_feature, newdata = test_classification)
confusionMatrix(svm_feature_test, reference = test_classification$diabetes)
```
